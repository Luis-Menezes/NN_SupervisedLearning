{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53c10d47",
   "metadata": {},
   "source": [
    "# Redes Neurais - Projeto 3\n",
    "# Modelos Generativos - Autoencoders Variacionais\n",
    "---------------------\n",
    "### Luis Filipe Menezes\n",
    "#### RA: 164924\n",
    "\n",
    "## 1. Objetivos:\n",
    "Este caderno consiste na terceira entrega da disciplina de Redes Neurais realizada no programa de Pós Graduação em Ciência da Computação durante meu mestrado.\n",
    "\n",
    "O projeto tem como objetivo:\n",
    "\n",
    "- Selecionar 2 datasets (rotulados)\n",
    "\n",
    "  - Treinar modelos VAEs:\n",
    "  \n",
    "  - Ajustar o melhor modelo (topologia) segundo a função de custo (conjunto validação)\n",
    "\n",
    "\n",
    "- Explorar o espaço latente:\n",
    "\n",
    "  - Gerar gráficos com a projeção do espaço latente em 2D (PCA)\n",
    "\n",
    "  - Usar os rótulos na projeção.\n",
    "\n",
    "- Algumas questões:\n",
    "\n",
    "  1. Há formação de clusters no espaço latente?\n",
    "  \n",
    "  2. Há separação dos rótulos no espaço latente?\n",
    "  \n",
    "  3. A projeção ilustra quanto da variância?\n",
    "\n",
    "- Adicional (opcional): Enviesar a formação do espaço latente com os exemplos rotulados\n",
    "\n",
    "\n",
    "Além disso, tentarei utilizar o PyTorch nesse projeto. A implementação será feita se baseando neste [material](https://lightning.ai/docs/pytorch/stable/notebooks/course_UvA-DL/08-deep-autoencoders.html) e nesta outra implementação de [autoencoder com MLP](https://debuggercafe.com/implementing-deep-autoencoder-in-pytorch/).\n",
    "\n",
    "Como o modelo que ele apresenta utiliza uma CNN no dataset Ciphar, como ainda não foi estudado CNNs irei utilizar uma MLP no dataset Fashion MNIST.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e2af28",
   "metadata": {},
   "source": [
    "### Bibliotecas utilizadas: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab955bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76e2930",
   "metadata": {},
   "source": [
    "## Dataset utilizado (Fashion MNIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcfb072",
   "metadata": {},
   "source": [
    "#### Setup do sistema para garantir reprodutibilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0036a0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f0554c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ebe90e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 500\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 1e-3\n",
    "LATENT_DIM = 12\n",
    "INPUT_DIM = 28 * 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f90286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = FashionMNIST(root='./FMNIST_data', train=True, download=False, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5409159",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = FashionMNIST(root='./FMNIST_data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e26bf885",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = torch.utils.data.random_split(train_dataset, [45000, 15000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0a9739",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, pin_memory=True, num_workers=4)\n",
    "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=True, drop_last=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c5c3d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "import os\n",
    "\n",
    "# utility functions\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda:0'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "def make_dir():\n",
    "    image_dir = 'FashionMNIST_Images'\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)\n",
    "def save_decoded_image(img, epoch):\n",
    "    img = img.view(img.size(0), 1, 28, 28)\n",
    "    save_image(img, './FashionMNIST_Images/linear_ae_image{}.png'.format(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f409f5fc",
   "metadata": {},
   "source": [
    "## Modelo em PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0caf0c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim: int):\n",
    "        \"\"\"Encoder.\n",
    "\n",
    "        Args:\n",
    "           latent_dim : Dimensionality of latent representation z\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = 28 * 28 # imagens do FashionMNIST são 28x28\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, latent_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2445798",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim: int):\n",
    "        \"\"\"Decoder.\n",
    "\n",
    "        Args:\n",
    "            latent_dim : Dimensionality of latent representation z\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = 28 * 28  # imagens do FashionMNIST são 28x28\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, self.output_dim),\n",
    "            nn.Sigmoid()  # para garantir que a saída esteja entre 0 e 1\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.net(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc528718",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(pl.LightningModule):\n",
    "    def __init__(self, latent_dim: int, learning_rate: float):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = Encoder(latent_dim)\n",
    "        self.decoder = Decoder(latent_dim)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon\n",
    "\n",
    "    # def training_step(self, batch, batch_idx):\n",
    "    #     x, _ = batch\n",
    "    #     x = x.view(x.size(0), -1)  # achata a imagem\n",
    "    #     x_recon = self.forward(x)\n",
    "    #     loss = self.criterion(x_recon, x)\n",
    "    #     self.log('train_loss', loss)\n",
    "    #     return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x_recon = self.forward(x)\n",
    "        loss = self.criterion(x_recon, x)\n",
    "        self.log('val_loss', loss)\n",
    "\n",
    "    # def configure_optimizers(self):\n",
    "    #     optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "    #     return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ee59a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_loader, NUM_EPOCHS, LEARNING_RATE):\n",
    "    optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.MSELoss()\n",
    "    net.to(get_device())\n",
    "    make_dir()\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (data, _) in enumerate(train_loader):\n",
    "            data = data.view(data.size(0), -1).to(get_device())\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(data)\n",
    "            loss = criterion(outputs, data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "        # Save reconstructed images for the first batch in the epoch\n",
    "        if epoch % 10 == 0 or epoch == NUM_EPOCHS - 1:\n",
    "            net.eval()\n",
    "            with torch.no_grad():\n",
    "                sample_data, _ = next(iter(train_loader))\n",
    "                sample_data = sample_data.view(sample_data.size(0), -1).to(get_device())\n",
    "                reconstructed = net(sample_data)\n",
    "                save_decoded_image(reconstructed.cpu(), epoch+1)\n",
    "            \n",
    "    return avg_loss\n",
    "    print('Training Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f0ffee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_image_reconstruction(net, testloader):\n",
    "     for batch in testloader:\n",
    "        img, _ = batch\n",
    "        img = img.to(device)\n",
    "        img = img.view(img.size(0), -1)\n",
    "        outputs = net(img)\n",
    "        outputs = outputs.view(outputs.size(0), 1, 28, 28).cpu().data\n",
    "        save_image(outputs, 'fashionmnist_reconstruction.png')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e034cfe",
   "metadata": {},
   "source": [
    "#### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2efffbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 0.7196\n",
      "Epoch [2/500], Loss: 0.6312\n",
      "Epoch [3/500], Loss: 0.6204\n",
      "Epoch [4/500], Loss: 0.6147\n",
      "Epoch [5/500], Loss: 0.6111\n",
      "Epoch [6/500], Loss: 0.6090\n",
      "Epoch [7/500], Loss: 0.6076\n",
      "Epoch [8/500], Loss: 0.6062\n",
      "Epoch [9/500], Loss: 0.6053\n",
      "Epoch [10/500], Loss: 0.6045\n",
      "Epoch [11/500], Loss: 0.6038\n",
      "Epoch [12/500], Loss: 0.6032\n",
      "Epoch [13/500], Loss: 0.6026\n",
      "Epoch [14/500], Loss: 0.6021\n",
      "Epoch [15/500], Loss: 0.6017\n",
      "Epoch [16/500], Loss: 0.6013\n",
      "Epoch [17/500], Loss: 0.6008\n",
      "Epoch [18/500], Loss: 0.6007\n",
      "Epoch [19/500], Loss: 0.6003\n",
      "Epoch [20/500], Loss: 0.6000\n",
      "Epoch [21/500], Loss: 0.5998\n",
      "Epoch [22/500], Loss: 0.5995\n",
      "Epoch [23/500], Loss: 0.5992\n",
      "Epoch [24/500], Loss: 0.5990\n",
      "Epoch [25/500], Loss: 0.5988\n",
      "Epoch [26/500], Loss: 0.5986\n",
      "Epoch [27/500], Loss: 0.5984\n",
      "Epoch [28/500], Loss: 0.5980\n",
      "Epoch [29/500], Loss: 0.5979\n",
      "Epoch [30/500], Loss: 0.5977\n",
      "Epoch [31/500], Loss: 0.5976\n",
      "Epoch [32/500], Loss: 0.5973\n",
      "Epoch [33/500], Loss: 0.5972\n",
      "Epoch [34/500], Loss: 0.5970\n",
      "Epoch [35/500], Loss: 0.5967\n",
      "Epoch [36/500], Loss: 0.5963\n",
      "Epoch [37/500], Loss: 0.5962\n",
      "Epoch [38/500], Loss: 0.5960\n",
      "Epoch [39/500], Loss: 0.5959\n",
      "Epoch [40/500], Loss: 0.5958\n",
      "Epoch [41/500], Loss: 0.5956\n",
      "Epoch [42/500], Loss: 0.5954\n",
      "Epoch [43/500], Loss: 0.5952\n",
      "Epoch [44/500], Loss: 0.5951\n",
      "Epoch [45/500], Loss: 0.5950\n",
      "Epoch [46/500], Loss: 0.5948\n",
      "Epoch [47/500], Loss: 0.5946\n",
      "Epoch [48/500], Loss: 0.5945\n",
      "Epoch [49/500], Loss: 0.5944\n",
      "Epoch [50/500], Loss: 0.5941\n",
      "Epoch [51/500], Loss: 0.5941\n",
      "Epoch [52/500], Loss: 0.5939\n",
      "Epoch [53/500], Loss: 0.5938\n",
      "Epoch [54/500], Loss: 0.5937\n",
      "Epoch [55/500], Loss: 0.5936\n",
      "Epoch [56/500], Loss: 0.5935\n",
      "Epoch [57/500], Loss: 0.5934\n",
      "Epoch [58/500], Loss: 0.5933\n",
      "Epoch [59/500], Loss: 0.5931\n",
      "Epoch [60/500], Loss: 0.5931\n",
      "Epoch [61/500], Loss: 0.5930\n",
      "Epoch [62/500], Loss: 0.5929\n",
      "Epoch [63/500], Loss: 0.5928\n",
      "Epoch [64/500], Loss: 0.5926\n",
      "Epoch [65/500], Loss: 0.5927\n",
      "Epoch [66/500], Loss: 0.5925\n",
      "Epoch [67/500], Loss: 0.5925\n",
      "Epoch [68/500], Loss: 0.5924\n",
      "Epoch [69/500], Loss: 0.5924\n",
      "Epoch [70/500], Loss: 0.5922\n",
      "Epoch [71/500], Loss: 0.5921\n",
      "Epoch [72/500], Loss: 0.5921\n",
      "Epoch [73/500], Loss: 0.5920\n",
      "Epoch [74/500], Loss: 0.5919\n",
      "Epoch [75/500], Loss: 0.5919\n",
      "Epoch [76/500], Loss: 0.5918\n",
      "Epoch [77/500], Loss: 0.5917\n",
      "Epoch [78/500], Loss: 0.5917\n",
      "Epoch [79/500], Loss: 0.5916\n",
      "Epoch [80/500], Loss: 0.5917\n",
      "Epoch [81/500], Loss: 0.5915\n",
      "Epoch [82/500], Loss: 0.5915\n",
      "Epoch [83/500], Loss: 0.5914\n",
      "Epoch [84/500], Loss: 0.5913\n",
      "Epoch [85/500], Loss: 0.5913\n",
      "Epoch [86/500], Loss: 0.5913\n",
      "Epoch [87/500], Loss: 0.5912\n",
      "Epoch [88/500], Loss: 0.5912\n",
      "Epoch [89/500], Loss: 0.5911\n",
      "Epoch [90/500], Loss: 0.5910\n",
      "Epoch [91/500], Loss: 0.5910\n",
      "Epoch [92/500], Loss: 0.5909\n",
      "Epoch [93/500], Loss: 0.5909\n",
      "Epoch [94/500], Loss: 0.5909\n",
      "Epoch [95/500], Loss: 0.5908\n",
      "Epoch [96/500], Loss: 0.5907\n",
      "Epoch [97/500], Loss: 0.5908\n",
      "Epoch [98/500], Loss: 0.5907\n",
      "Epoch [99/500], Loss: 0.5907\n",
      "Epoch [100/500], Loss: 0.5905\n",
      "Epoch [101/500], Loss: 0.5905\n",
      "Epoch [102/500], Loss: 0.5905\n",
      "Epoch [103/500], Loss: 0.5904\n",
      "Epoch [104/500], Loss: 0.5903\n",
      "Epoch [105/500], Loss: 0.5905\n",
      "Epoch [106/500], Loss: 0.5903\n",
      "Epoch [107/500], Loss: 0.5902\n",
      "Epoch [108/500], Loss: 0.5902\n",
      "Epoch [109/500], Loss: 0.5902\n",
      "Epoch [110/500], Loss: 0.5902\n",
      "Epoch [111/500], Loss: 0.5903\n",
      "Epoch [112/500], Loss: 0.5901\n",
      "Epoch [113/500], Loss: 0.5900\n",
      "Epoch [114/500], Loss: 0.5900\n",
      "Epoch [115/500], Loss: 0.5900\n",
      "Epoch [116/500], Loss: 0.5899\n",
      "Epoch [117/500], Loss: 0.5898\n",
      "Epoch [118/500], Loss: 0.5899\n",
      "Epoch [119/500], Loss: 0.5899\n",
      "Epoch [120/500], Loss: 0.5899\n",
      "Epoch [121/500], Loss: 0.5899\n",
      "Epoch [122/500], Loss: 0.5897\n",
      "Epoch [123/500], Loss: 0.5897\n",
      "Epoch [124/500], Loss: 0.5897\n",
      "Epoch [125/500], Loss: 0.5896\n",
      "Epoch [126/500], Loss: 0.5897\n",
      "Epoch [127/500], Loss: 0.5896\n",
      "Epoch [128/500], Loss: 0.5896\n",
      "Epoch [129/500], Loss: 0.5896\n",
      "Epoch [130/500], Loss: 0.5895\n",
      "Epoch [131/500], Loss: 0.5895\n",
      "Epoch [132/500], Loss: 0.5896\n",
      "Epoch [133/500], Loss: 0.5895\n",
      "Epoch [134/500], Loss: 0.5895\n",
      "Epoch [135/500], Loss: 0.5895\n",
      "Epoch [136/500], Loss: 0.5895\n",
      "Epoch [137/500], Loss: 0.5893\n",
      "Epoch [138/500], Loss: 0.5894\n",
      "Epoch [139/500], Loss: 0.5894\n",
      "Epoch [140/500], Loss: 0.5894\n",
      "Epoch [141/500], Loss: 0.5894\n",
      "Epoch [142/500], Loss: 0.5894\n",
      "Epoch [143/500], Loss: 0.5892\n",
      "Epoch [144/500], Loss: 0.5892\n",
      "Epoch [145/500], Loss: 0.5893\n",
      "Epoch [146/500], Loss: 0.5892\n",
      "Epoch [147/500], Loss: 0.5892\n",
      "Epoch [148/500], Loss: 0.5892\n",
      "Epoch [149/500], Loss: 0.5892\n",
      "Epoch [150/500], Loss: 0.5891\n",
      "Epoch [151/500], Loss: 0.5891\n",
      "Epoch [152/500], Loss: 0.5891\n",
      "Epoch [153/500], Loss: 0.5891\n",
      "Epoch [154/500], Loss: 0.5891\n",
      "Epoch [155/500], Loss: 0.5890\n",
      "Epoch [156/500], Loss: 0.5890\n",
      "Epoch [157/500], Loss: 0.5889\n",
      "Epoch [158/500], Loss: 0.5891\n",
      "Epoch [159/500], Loss: 0.5889\n",
      "Epoch [160/500], Loss: 0.5890\n",
      "Epoch [161/500], Loss: 0.5889\n",
      "Epoch [162/500], Loss: 0.5890\n",
      "Epoch [163/500], Loss: 0.5890\n",
      "Epoch [164/500], Loss: 0.5889\n",
      "Epoch [165/500], Loss: 0.5890\n",
      "Epoch [166/500], Loss: 0.5889\n",
      "Epoch [167/500], Loss: 0.5889\n",
      "Epoch [168/500], Loss: 0.5889\n",
      "Epoch [169/500], Loss: 0.5887\n",
      "Epoch [170/500], Loss: 0.5889\n",
      "Epoch [171/500], Loss: 0.5888\n",
      "Epoch [172/500], Loss: 0.5888\n",
      "Epoch [173/500], Loss: 0.5887\n",
      "Epoch [174/500], Loss: 0.5887\n",
      "Epoch [175/500], Loss: 0.5888\n",
      "Epoch [176/500], Loss: 0.5887\n",
      "Epoch [177/500], Loss: 0.5887\n",
      "Epoch [178/500], Loss: 0.5887\n",
      "Epoch [179/500], Loss: 0.5888\n",
      "Epoch [180/500], Loss: 0.5888\n",
      "Epoch [181/500], Loss: 0.5887\n",
      "Epoch [182/500], Loss: 0.5885\n",
      "Epoch [183/500], Loss: 0.5887\n",
      "Epoch [184/500], Loss: 0.5886\n",
      "Epoch [185/500], Loss: 0.5886\n",
      "Epoch [186/500], Loss: 0.5887\n",
      "Epoch [187/500], Loss: 0.5887\n",
      "Epoch [188/500], Loss: 0.5886\n",
      "Epoch [189/500], Loss: 0.5886\n",
      "Epoch [190/500], Loss: 0.5886\n",
      "Epoch [191/500], Loss: 0.5885\n",
      "Epoch [192/500], Loss: 0.5885\n",
      "Epoch [193/500], Loss: 0.5884\n",
      "Epoch [194/500], Loss: 0.5886\n",
      "Epoch [195/500], Loss: 0.5884\n",
      "Epoch [196/500], Loss: 0.5884\n",
      "Epoch [197/500], Loss: 0.5885\n",
      "Epoch [198/500], Loss: 0.5886\n",
      "Epoch [199/500], Loss: 0.5884\n",
      "Epoch [200/500], Loss: 0.5885\n",
      "Epoch [201/500], Loss: 0.5884\n",
      "Epoch [202/500], Loss: 0.5884\n",
      "Epoch [203/500], Loss: 0.5884\n",
      "Epoch [204/500], Loss: 0.5883\n",
      "Epoch [205/500], Loss: 0.5884\n",
      "Epoch [206/500], Loss: 0.5883\n",
      "Epoch [207/500], Loss: 0.5883\n",
      "Epoch [208/500], Loss: 0.5884\n",
      "Epoch [209/500], Loss: 0.5882\n",
      "Epoch [210/500], Loss: 0.5883\n",
      "Epoch [211/500], Loss: 0.5884\n",
      "Epoch [212/500], Loss: 0.5883\n",
      "Epoch [213/500], Loss: 0.5882\n",
      "Epoch [214/500], Loss: 0.5883\n",
      "Epoch [215/500], Loss: 0.5883\n",
      "Epoch [216/500], Loss: 0.5883\n",
      "Epoch [217/500], Loss: 0.5883\n",
      "Epoch [218/500], Loss: 0.5882\n",
      "Epoch [219/500], Loss: 0.5882\n",
      "Epoch [220/500], Loss: 0.5882\n",
      "Epoch [221/500], Loss: 0.5881\n",
      "Epoch [222/500], Loss: 0.5883\n",
      "Epoch [223/500], Loss: 0.5882\n",
      "Epoch [224/500], Loss: 0.5881\n",
      "Epoch [225/500], Loss: 0.5882\n",
      "Epoch [226/500], Loss: 0.5882\n",
      "Epoch [227/500], Loss: 0.5882\n",
      "Epoch [228/500], Loss: 0.5881\n",
      "Epoch [229/500], Loss: 0.5882\n",
      "Epoch [230/500], Loss: 0.5882\n",
      "Epoch [231/500], Loss: 0.5880\n",
      "Epoch [232/500], Loss: 0.5881\n",
      "Epoch [233/500], Loss: 0.5881\n",
      "Epoch [234/500], Loss: 0.5882\n",
      "Epoch [235/500], Loss: 0.5880\n",
      "Epoch [236/500], Loss: 0.5880\n",
      "Epoch [237/500], Loss: 0.5881\n",
      "Epoch [238/500], Loss: 0.5881\n",
      "Epoch [239/500], Loss: 0.5881\n",
      "Epoch [240/500], Loss: 0.5880\n",
      "Epoch [241/500], Loss: 0.5881\n",
      "Epoch [242/500], Loss: 0.5880\n",
      "Epoch [243/500], Loss: 0.5880\n",
      "Epoch [244/500], Loss: 0.5879\n",
      "Epoch [245/500], Loss: 0.5880\n",
      "Epoch [246/500], Loss: 0.5881\n",
      "Epoch [247/500], Loss: 0.5880\n",
      "Epoch [248/500], Loss: 0.5880\n",
      "Epoch [249/500], Loss: 0.5879\n",
      "Epoch [250/500], Loss: 0.5880\n",
      "Epoch [251/500], Loss: 0.5880\n",
      "Epoch [252/500], Loss: 0.5878\n",
      "Epoch [253/500], Loss: 0.5879\n",
      "Epoch [254/500], Loss: 0.5880\n",
      "Epoch [255/500], Loss: 0.5879\n",
      "Epoch [256/500], Loss: 0.5879\n",
      "Epoch [257/500], Loss: 0.5879\n",
      "Epoch [258/500], Loss: 0.5878\n",
      "Epoch [259/500], Loss: 0.5878\n",
      "Epoch [260/500], Loss: 0.5880\n",
      "Epoch [261/500], Loss: 0.5878\n",
      "Epoch [262/500], Loss: 0.5878\n",
      "Epoch [263/500], Loss: 0.5878\n",
      "Epoch [264/500], Loss: 0.5879\n",
      "Epoch [265/500], Loss: 0.5878\n",
      "Epoch [266/500], Loss: 0.5878\n",
      "Epoch [267/500], Loss: 0.5878\n",
      "Epoch [268/500], Loss: 0.5879\n",
      "Epoch [269/500], Loss: 0.5878\n",
      "Epoch [270/500], Loss: 0.5878\n",
      "Epoch [271/500], Loss: 0.5878\n",
      "Epoch [272/500], Loss: 0.5878\n",
      "Epoch [273/500], Loss: 0.5878\n",
      "Epoch [274/500], Loss: 0.5878\n",
      "Epoch [275/500], Loss: 0.5877\n",
      "Epoch [276/500], Loss: 0.5877\n",
      "Epoch [277/500], Loss: 0.5877\n",
      "Epoch [278/500], Loss: 0.5878\n",
      "Epoch [279/500], Loss: 0.5877\n",
      "Epoch [280/500], Loss: 0.5878\n",
      "Epoch [281/500], Loss: 0.5877\n",
      "Epoch [282/500], Loss: 0.5877\n",
      "Epoch [283/500], Loss: 0.5876\n",
      "Epoch [284/500], Loss: 0.5877\n",
      "Epoch [285/500], Loss: 0.5877\n",
      "Epoch [286/500], Loss: 0.5878\n",
      "Epoch [287/500], Loss: 0.5878\n",
      "Epoch [288/500], Loss: 0.5877\n",
      "Epoch [289/500], Loss: 0.5876\n",
      "Epoch [290/500], Loss: 0.5877\n",
      "Epoch [291/500], Loss: 0.5876\n",
      "Epoch [292/500], Loss: 0.5875\n",
      "Epoch [293/500], Loss: 0.5877\n",
      "Epoch [294/500], Loss: 0.5877\n",
      "Epoch [295/500], Loss: 0.5876\n",
      "Epoch [296/500], Loss: 0.5877\n",
      "Epoch [297/500], Loss: 0.5876\n",
      "Epoch [298/500], Loss: 0.5876\n",
      "Epoch [299/500], Loss: 0.5876\n",
      "Epoch [300/500], Loss: 0.5877\n",
      "Epoch [301/500], Loss: 0.5876\n",
      "Epoch [302/500], Loss: 0.5875\n",
      "Epoch [303/500], Loss: 0.5875\n",
      "Epoch [304/500], Loss: 0.5875\n",
      "Epoch [305/500], Loss: 0.5875\n",
      "Epoch [306/500], Loss: 0.5876\n",
      "Epoch [307/500], Loss: 0.5875\n",
      "Epoch [308/500], Loss: 0.5876\n",
      "Epoch [309/500], Loss: 0.5876\n",
      "Epoch [310/500], Loss: 0.5875\n",
      "Epoch [311/500], Loss: 0.5875\n",
      "Epoch [312/500], Loss: 0.5874\n",
      "Epoch [313/500], Loss: 0.5875\n",
      "Epoch [314/500], Loss: 0.5875\n",
      "Epoch [315/500], Loss: 0.5875\n",
      "Epoch [316/500], Loss: 0.5874\n",
      "Epoch [317/500], Loss: 0.5875\n",
      "Epoch [318/500], Loss: 0.5875\n",
      "Epoch [319/500], Loss: 0.5875\n",
      "Epoch [320/500], Loss: 0.5874\n",
      "Epoch [321/500], Loss: 0.5874\n",
      "Epoch [322/500], Loss: 0.5875\n",
      "Epoch [323/500], Loss: 0.5874\n",
      "Epoch [324/500], Loss: 0.5875\n",
      "Epoch [325/500], Loss: 0.5874\n",
      "Epoch [326/500], Loss: 0.5875\n",
      "Epoch [327/500], Loss: 0.5876\n",
      "Epoch [328/500], Loss: 0.5874\n",
      "Epoch [329/500], Loss: 0.5874\n",
      "Epoch [330/500], Loss: 0.5875\n",
      "Epoch [331/500], Loss: 0.5875\n",
      "Epoch [332/500], Loss: 0.5874\n",
      "Epoch [333/500], Loss: 0.5874\n",
      "Epoch [334/500], Loss: 0.5875\n",
      "Epoch [335/500], Loss: 0.5874\n",
      "Epoch [336/500], Loss: 0.5874\n",
      "Epoch [337/500], Loss: 0.5875\n",
      "Epoch [338/500], Loss: 0.5874\n",
      "Epoch [339/500], Loss: 0.5874\n",
      "Epoch [340/500], Loss: 0.5874\n",
      "Epoch [341/500], Loss: 0.5874\n",
      "Epoch [342/500], Loss: 0.5875\n",
      "Epoch [343/500], Loss: 0.5874\n",
      "Epoch [344/500], Loss: 0.5874\n",
      "Epoch [345/500], Loss: 0.5873\n",
      "Epoch [346/500], Loss: 0.5874\n",
      "Epoch [347/500], Loss: 0.5874\n",
      "Epoch [348/500], Loss: 0.5873\n",
      "Epoch [349/500], Loss: 0.5874\n",
      "Epoch [350/500], Loss: 0.5874\n",
      "Epoch [351/500], Loss: 0.5872\n",
      "Epoch [352/500], Loss: 0.5873\n",
      "Epoch [353/500], Loss: 0.5874\n",
      "Epoch [354/500], Loss: 0.5873\n",
      "Epoch [355/500], Loss: 0.5875\n",
      "Epoch [356/500], Loss: 0.5873\n",
      "Epoch [357/500], Loss: 0.5873\n",
      "Epoch [358/500], Loss: 0.5874\n",
      "Epoch [359/500], Loss: 0.5873\n",
      "Epoch [360/500], Loss: 0.5872\n",
      "Epoch [361/500], Loss: 0.5874\n",
      "Epoch [362/500], Loss: 0.5873\n",
      "Epoch [363/500], Loss: 0.5874\n",
      "Epoch [364/500], Loss: 0.5872\n",
      "Epoch [365/500], Loss: 0.5873\n",
      "Epoch [366/500], Loss: 0.5873\n",
      "Epoch [367/500], Loss: 0.5872\n",
      "Epoch [368/500], Loss: 0.5874\n",
      "Epoch [369/500], Loss: 0.5873\n",
      "Epoch [370/500], Loss: 0.5873\n",
      "Epoch [371/500], Loss: 0.5873\n",
      "Epoch [372/500], Loss: 0.5873\n",
      "Epoch [373/500], Loss: 0.5872\n",
      "Epoch [374/500], Loss: 0.5873\n",
      "Epoch [375/500], Loss: 0.5873\n",
      "Epoch [376/500], Loss: 0.5873\n",
      "Epoch [377/500], Loss: 0.5873\n",
      "Epoch [378/500], Loss: 0.5872\n",
      "Epoch [379/500], Loss: 0.5873\n",
      "Epoch [380/500], Loss: 0.5873\n",
      "Epoch [381/500], Loss: 0.5873\n",
      "Epoch [382/500], Loss: 0.5872\n",
      "Epoch [383/500], Loss: 0.5872\n",
      "Epoch [384/500], Loss: 0.5872\n",
      "Epoch [385/500], Loss: 0.5872\n",
      "Epoch [386/500], Loss: 0.5873\n",
      "Epoch [387/500], Loss: 0.5873\n",
      "Epoch [388/500], Loss: 0.5872\n",
      "Epoch [389/500], Loss: 0.5873\n",
      "Epoch [390/500], Loss: 0.5871\n",
      "Epoch [391/500], Loss: 0.5871\n",
      "Epoch [392/500], Loss: 0.5872\n",
      "Epoch [393/500], Loss: 0.5873\n",
      "Epoch [394/500], Loss: 0.5872\n",
      "Epoch [395/500], Loss: 0.5871\n",
      "Epoch [396/500], Loss: 0.5872\n",
      "Epoch [397/500], Loss: 0.5873\n",
      "Epoch [398/500], Loss: 0.5872\n",
      "Epoch [399/500], Loss: 0.5873\n",
      "Epoch [400/500], Loss: 0.5872\n",
      "Epoch [401/500], Loss: 0.5872\n",
      "Epoch [402/500], Loss: 0.5872\n",
      "Epoch [403/500], Loss: 0.5872\n",
      "Epoch [404/500], Loss: 0.5872\n",
      "Epoch [405/500], Loss: 0.5872\n",
      "Epoch [406/500], Loss: 0.5872\n",
      "Epoch [407/500], Loss: 0.5871\n",
      "Epoch [408/500], Loss: 0.5872\n",
      "Epoch [409/500], Loss: 0.5871\n",
      "Epoch [410/500], Loss: 0.5872\n",
      "Epoch [411/500], Loss: 0.5871\n",
      "Epoch [412/500], Loss: 0.5871\n",
      "Epoch [413/500], Loss: 0.5870\n",
      "Epoch [414/500], Loss: 0.5872\n",
      "Epoch [415/500], Loss: 0.5871\n",
      "Epoch [416/500], Loss: 0.5872\n",
      "Epoch [417/500], Loss: 0.5871\n",
      "Epoch [418/500], Loss: 0.5870\n",
      "Epoch [419/500], Loss: 0.5871\n",
      "Epoch [420/500], Loss: 0.5871\n",
      "Epoch [421/500], Loss: 0.5870\n",
      "Epoch [422/500], Loss: 0.5871\n",
      "Epoch [423/500], Loss: 0.5870\n",
      "Epoch [424/500], Loss: 0.5871\n",
      "Epoch [425/500], Loss: 0.5872\n",
      "Epoch [426/500], Loss: 0.5871\n",
      "Epoch [427/500], Loss: 0.5872\n",
      "Epoch [428/500], Loss: 0.5871\n",
      "Epoch [429/500], Loss: 0.5871\n",
      "Epoch [430/500], Loss: 0.5870\n",
      "Epoch [431/500], Loss: 0.5871\n",
      "Epoch [432/500], Loss: 0.5872\n",
      "Epoch [433/500], Loss: 0.5871\n",
      "Epoch [434/500], Loss: 0.5871\n",
      "Epoch [435/500], Loss: 0.5871\n",
      "Epoch [436/500], Loss: 0.5869\n",
      "Epoch [437/500], Loss: 0.5871\n",
      "Epoch [438/500], Loss: 0.5871\n",
      "Epoch [439/500], Loss: 0.5870\n",
      "Epoch [440/500], Loss: 0.5871\n",
      "Epoch [441/500], Loss: 0.5870\n",
      "Epoch [442/500], Loss: 0.5870\n",
      "Epoch [443/500], Loss: 0.5871\n",
      "Epoch [444/500], Loss: 0.5871\n",
      "Epoch [445/500], Loss: 0.5870\n",
      "Epoch [446/500], Loss: 0.5870\n",
      "Epoch [447/500], Loss: 0.5870\n",
      "Epoch [448/500], Loss: 0.5871\n",
      "Epoch [449/500], Loss: 0.5871\n",
      "Epoch [450/500], Loss: 0.5870\n",
      "Epoch [451/500], Loss: 0.5870\n",
      "Epoch [452/500], Loss: 0.5871\n",
      "Epoch [453/500], Loss: 0.5870\n",
      "Epoch [454/500], Loss: 0.5869\n",
      "Epoch [455/500], Loss: 0.5869\n",
      "Epoch [456/500], Loss: 0.5871\n",
      "Epoch [457/500], Loss: 0.5869\n",
      "Epoch [458/500], Loss: 0.5870\n",
      "Epoch [459/500], Loss: 0.5870\n",
      "Epoch [460/500], Loss: 0.5870\n",
      "Epoch [461/500], Loss: 0.5870\n",
      "Epoch [462/500], Loss: 0.5869\n",
      "Epoch [463/500], Loss: 0.5869\n",
      "Epoch [464/500], Loss: 0.5872\n",
      "Epoch [465/500], Loss: 0.5870\n",
      "Epoch [466/500], Loss: 0.5870\n",
      "Epoch [467/500], Loss: 0.5869\n",
      "Epoch [468/500], Loss: 0.5869\n",
      "Epoch [469/500], Loss: 0.5870\n",
      "Epoch [470/500], Loss: 0.5870\n",
      "Epoch [471/500], Loss: 0.5870\n",
      "Epoch [472/500], Loss: 0.5870\n",
      "Epoch [473/500], Loss: 0.5870\n",
      "Epoch [474/500], Loss: 0.5870\n",
      "Epoch [475/500], Loss: 0.5868\n",
      "Epoch [476/500], Loss: 0.5869\n",
      "Epoch [477/500], Loss: 0.5870\n",
      "Epoch [478/500], Loss: 0.5869\n",
      "Epoch [479/500], Loss: 0.5869\n",
      "Epoch [480/500], Loss: 0.5869\n",
      "Epoch [481/500], Loss: 0.5870\n",
      "Epoch [482/500], Loss: 0.5869\n",
      "Epoch [483/500], Loss: 0.5870\n",
      "Epoch [484/500], Loss: 0.5869\n",
      "Epoch [485/500], Loss: 0.5869\n",
      "Epoch [486/500], Loss: 0.5870\n",
      "Epoch [487/500], Loss: 0.5869\n",
      "Epoch [488/500], Loss: 0.5869\n",
      "Epoch [489/500], Loss: 0.5869\n",
      "Epoch [490/500], Loss: 0.5870\n",
      "Epoch [491/500], Loss: 0.5869\n",
      "Epoch [492/500], Loss: 0.5869\n",
      "Epoch [493/500], Loss: 0.5869\n",
      "Epoch [494/500], Loss: 0.5869\n",
      "Epoch [495/500], Loss: 0.5870\n",
      "Epoch [496/500], Loss: 0.5869\n",
      "Epoch [497/500], Loss: 0.5868\n",
      "Epoch [498/500], Loss: 0.5869\n",
      "Epoch [499/500], Loss: 0.5869\n",
      "Epoch [500/500], Loss: 0.5869\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# train the network\n",
    "vae = AutoEncoder(latent_dim=LATENT_DIM, learning_rate=LEARNING_RATE)\n",
    "# net = vae.to(get_device())\n",
    "train_loss = train(vae, train_loader, NUM_EPOCHS, LEARNING_RATE)\n",
    "plt.figure()\n",
    "plt.plot(train_loss)\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('deep_ae_fashionmnist_loss.png')\n",
    "\n",
    "# test the network\n",
    "test_image_reconstruction(vae, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
